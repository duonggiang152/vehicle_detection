{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:18:42.507666: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-28 11:18:42.518102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740716322.530084  295672 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740716322.533461  295672 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-28 11:18:42.546068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1740716324.424034  295672 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9257 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "\n",
    "model = tf.saved_model.load(\"./exported_model\")\n",
    "model_fn = model.signatures['serving_default']\n",
    "tracker = DeepSort(max_age=5,max_iou_distance=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(INPUT_WIDTH, INPUT_HEIGHT) = (256, 256) \n",
    "SCORE_THRESHOLD = 0.3\n",
    "def detect_objects(image):\n",
    "\n",
    "    resized_image = cv2.resize(src=image, dsize=(INPUT_WIDTH,INPUT_HEIGHT))\n",
    "    input_tensor = tf.convert_to_tensor(resized_image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    detections = model_fn(input_tensor)\n",
    "\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    return boxes, classes, scores, resized_image\n",
    "\n",
    "def convert_to_deepsort_format(boxes, classes, scores):\n",
    "    objects = []\n",
    "    for i in range(len(boxes)):\n",
    "        if classes[i] in [1]: \n",
    "            x_min, y_min, x_max, y_max = boxes[i]\n",
    "            score = scores[i]\n",
    "            if score > SCORE_THRESHOLD:\n",
    "                left = x_min\n",
    "                top = y_min\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                objects.append(([left, top, width, height], float(score), 1))\n",
    "\n",
    "    return objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to draw bounding boxes\n",
    "original_width, original_height = 256, 256\n",
    "\n",
    "# New image size\n",
    "new_width, new_height = 1280, 720\n",
    "scale_x = new_width / original_width\n",
    "scale_y = new_height / original_height\n",
    "def draw_boxes_track(image, tracks):\n",
    "    global scale_x, scale_y\n",
    "    for track in tracks:\n",
    "        y_min, x_min, y_max, x_max = track.to_tlbr().astype(int)\n",
    "        y_min = int(y_min*scale_y)\n",
    "        x_min = int(x_min*scale_x)\n",
    "        y_max = int(y_max*scale_y)\n",
    "        x_max = int(x_max*scale_x)\n",
    "        track_id = track.track_id\n",
    "      \n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "      \n",
    "        label = f\"ID: {track_id}\"\n",
    "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 2)\n",
    "    return image\n",
    "def draw_boxes_detect(image, boxes, scores, score_threshold):\n",
    "    for i in range(len(boxes)):\n",
    "        y_min, x_min, y_max, x_max = boxes[i].astype(int)\n",
    "        if scores[i] <= score_threshold:\n",
    "            continue\n",
    "      \n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 1)\n",
    "      \n",
    "        label = f\"Car\"\n",
    "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"/home/giang/Downloads/test2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter(\"output1.mp4\", fourcc, 24, (frame_width * 2, frame_height))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "    origin_frame = frame.copy()\n",
    "    # origin_frame= cv2.cvtColor(origin_frame, cv2.COLOR_BGR2RGB)\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, classes, scores, resized_image = detect_objects(frame)\n",
    "    objects = convert_to_deepsort_format(boxes, classes, scores)\n",
    "    if len(objects) > 0:\n",
    "        tracks = tracker.update_tracks(objects, frame=resized_image)\n",
    "    else:\n",
    "        tracks = []\n",
    "\n",
    "    \n",
    "    outputImage = draw_boxes_track(frame, tracks)\n",
    "    concatenated_frame = cv2.hconcat([origin_frame, outputImage])\n",
    "    out.write(concatenated_frame)\n",
    "    # plt.imshow(concatenated_frame)\n",
    "    # plt.show()\n",
    "    \n",
    "    # clear_output(wait=True)  \n",
    "    \n",
    "    # time.sleep(0.1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/giang/vehicle_detection\n"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
